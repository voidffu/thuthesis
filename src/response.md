# 学位论文评阅意见答复及论文修改说明

## 对评阅人1意见的回复及逐条修改说明
### 整体回复
感谢评阅专家对论文的细致评阅与宝贵建议。专家所提出的意见涉及模型鲁棒性实验验证、专业缩略语规范、论文结构优化以及图表标题简化等方面，这些意见切中肯綮，对论文质量提升具有重要指导意义。已根据专家建议进行了全面修改和补充，包括增加新数据集实验验证鲁棒性、规范专业术语表述、优化章节结构、简化图表标题等，这些修改使论文在学术严谨性和可读性方面得到了显著提升。

### 意见1：
建议可以补充与其他新兴多模态大模型（如基于大语言模型的方案）进行横向对比和复杂光照下鲁棒性验证实验。
### 说明：
衷心感谢专家提出的富有洞见的建议。
关于与新兴多模态大模型的横向对比，本文所提出的MDSI是一种可插拔方法，这一特性使其能够作为通用的功能增强组件无缝集成到各种主干网络中，包括传统网络架构和大模型架构。本文的设计理念与大模型并非竞争关系，而是可以互为补充——MDSI可以作为大模型的功能增强模块提升其多模态处理能力。未来可以考虑进一步探索本文方法与更多大模型主干网络集成时的性能表现，已在第5.2节研究展望的第（1）点中补充了相关讨论
<!-- "本文证明了 MDSI 灵活、可插拔的特性使其能够无缝集成到各种架构中，并能轻松适应其他领域，例如动作识别和手语识别。由于集成所需的调整很少，进一步探索 MDSI 与各种主干的集成仍然是一个有价值的方向，例如与新兴的多模态大模型结合可能带来增强的效果，并且轻微的定制可以产生有益的结果。" -->
此外需要说明的是，本文在现有的实验设计中已经与当前领域内的先进方法进行了全面对比，实验结果显示MDSI在多个基准上实现了最优表现，充分证明了方法的优越性。


关于复杂光照下的鲁棒性验证，原有实验设计与数据集已经涵盖了多种复杂光照条件、背景变化和手势者差异，如论文图x、y、z所示，所提方法在这些具有挑战性的场景中表现出色，证明了其在实际复杂环境中的应用潜力。
在此基础上，针对专家建议，本研究进一步扩展了验证实验，补充了基于AUTSL大规模手语数据集的跨场景测试。该数据集同样包含丰富的光照条件和背景，实验结果详见第4.5节和图4.5，进一步证明了所提方法在复杂环境下的鲁棒性与泛化能力。
<!-- "识别准确率。为了评估系统的识别准确性与鲁棒性，本文分别在公开数据集和自采数据集上进行了实验。如图 4.5 所示，两数据集均包含复杂光照、背景、手势者等具有挑战性的场景，以及 RGB 和深度多种模态。
• 公开数据集：AUTSL 大规模手语数据集[137] ，包括 43 个不同的手语者执行的 226 种手语，总共 38,336 个孤立的手语视频样本。样本包含各种室内、室外背景与不同的手语者姿势（图 4.5(a)）。每个样本都使用 Microsoft Kinect v2 记录，并包含彩色图像（RGB）、深度和骨架模态。
• 自采数据集：使用商业级奥比中光 RGB-D 相机（图 4.4）构建了自采数据集，并基于此评估了本文的方法。共采集了 12 类数据，每类包含 25 个样本（图 4.5(b)）。采集过程遵循[16] 的设置，采集分辨率为 320 × 240，平均帧数32，每帧同时包含 RGB 图像和 Depth 图像。
结果显示，所提出的识别算法，在 AUSTL 大规模手语数据集上的 RGB 模态识别准确率达到了 92.08%，在自采数据集上的 RGB-D 模态识别准确率达到了 99.27%，验证了所提出方法在实际应用场景中的泛化性、鲁棒性与可靠性。” -->

### 意见2：
专业缩略语首次出现，要给出英文的全称，对读者更友好。
### 说明：
非常感谢专家的细致建议。为增强论文的可读性和规范性，已针对专业缩略语做如下修订：
- 在论文正文前新增"符号和缩略语说明"部分（位于第X页），系统性地列出了论文中所有涉及的专业缩略语及其对应的英文全称和中文解释。
- 同时，也在正文中首次出现各专业缩略语的位置补充了相应的英文全称，例如在第1.1节第二段：
<!-- “一方面，手势识别（Hand Gesture Recognition，HGR）技术可以...另一方面，手势生成（Hand Gesture 
Generation，HGG）技术可以...” -->

### 意见3：
第2章内容建议和1.2合并介绍，不用另起一章，并且一些知识和后面直接关联性也不强。
### 说明：
诚挚感谢专家对论文结构的优化建议。经过认真考虑，已将原第2章内容与第1.2节合并，重新组织为更为紧凑的相关工作与背景介绍部分。合并后的内容详见修改后论文的第1.2节。

### 意见4：
第3、4章标题的“研究”建议删除，更简洁，包括4.5.6标题“更多”都可以删除。中文插图和表格的标题要简洁，不要将英文直接翻译过来。
### 说明：
衷心感谢专家对论文标题和图表表述的宝贵建议，已针对论文做如下修订：
- 对第3章、第4章及其子章节的标题进行了精简修改，删除了冗余词汇如"研究"和"更多"等，使标题更加简洁明了。
- 对全文的图表标题进行了全面检查和修改，确保采用符合中文表达习惯的简练表述方式。例如图1.2：
<!-- 修改前：RGB-D 手势识别的主要挑战可归因于两个因素：(i) 信息冗余 (IR) 存在于类内，尤其是背景、照明和视角。(ii) 信息缺失 (IA) 存在于类间，尤其是视觉上相似的手势。
修改后：RGB-D 手势识别面临两个主要挑战：(i)类内信息冗余 (IR)。(ii) 类间信息缺失 (IA)。 -->

## 对评阅人2意见的回复及逐条修改说明
### 整体回复
衷心感谢评阅专家提出的宝贵意见和建议。专家的评阅意见主要聚焦于鲁棒性实验验证、模型理论推导细节以及系统交互功能的拓展性三个方面，这些意见对提升论文学术质量和应用价值具有关键作用。已根据专家建议进行了详尽的修改，包括补充了大规模真实场景数据集验证、完善了扩散模型的理论推导，并在未来展望中明确了系统交互与动态扩展的发展方向。这些修改不仅使论文更加严谨完整，也为后续研究指明了方向。

### 意见1：
实验仅基于标准的实验室环境数据集，建议补充一些真实场景的测试（如遮挡手势、动态光照等等），以验证鲁棒性。
### 说明：
非常感谢专家对实验验证部分的建设性意见。为了充分验证方法在真实场景中的鲁棒性，已在实验部分补充了基于AUTSL大规模手语数据集的实验验证。该数据集包含43位不同手语者在各种自然光照和背景条件下执行的226种手语，总计38,336个样本，具有丰富的环境变化和姿态多样性。同时，原有的自采数据集也涵盖了不同光照条件和背景变化，能够在一定程度上模拟真实应用场景。实验结果显示，所提方法在AUTSL数据集的RGB模态上达到了92.08%的识别准确率，在自采数据集的RGB-D模态上达到了99.27%的识别准确率，充分证明了方法在复杂环境下的鲁棒性和泛化能力。
关于遮挡手势的测试，由于在实际应用场景中手语交流通常不会出现严重遮挡情况，且遮挡会显著影响交流效果，因此本研究暂未将其纳入考虑范围。

### 意见2：
扩散模型的训练过程描述较简略，建议补充关键公式推导。
### 说明：
衷心感谢专家的细致建议。已在第3.2节中补充了扩散模型训练过程的详细细节与关键公式。具体而言，增加了前向扩散过程的数学表述（式3.2和式3.3），详细阐述了噪声加入机制和马尔可夫链转移过程；补充了反向扩散过程的理论基础，包括无分类器指导的采样策略（式3.4）；并明确了训练优化目标函数（式3.5）。这些补充内容使扩散模型的理论框架更加完整，为读者提供了更为深入理解算法原理的理论基础，也增强了论文的学术严谨性。

### 意见3：
当前系统以视觉交互为主，交互单一，同时手势生成仅支持预定义词汇，缺乏动态扩展能力，可探索增量学习机制。
### 说明：
诚挚感谢专家对系统功能扩展的前瞻性建议。针对交互方式单一的问题，已在系统未来发展规划中考虑引入多模态交互机制，丰富用户体验。关于手势生成与识别的动态扩展能力，需要说明的是，当前手势生成模块具备动态词汇扩展能力，可以生成训练集之外的新词汇手势。而对于识别模块的动态扩展，在未来考虑纳入主动学习的方式以实现增量学习。
已在第5.2节研究展望的第（3）点中添加了相关讨论与展望：
<!-- 此外，系统的交互体验和个性化学习支持也有待进一步优化。当前系统交互以视觉为主，未来可以引入语音、触觉等多模态交互，并探索基于增强现实的沉浸式学习环境；最后，系统的动态扩展能力可进一步加强，虽然目前手势生成模块支持自由灵活的词汇生成、但手势识别模块目前仅支持预定义的词汇评估。未来可以探索基于主动学习的在线增量学习机制，使系统能够从用户交互中持续学习新的手语词汇和动作，动态扩展识别和生成能力。 -->